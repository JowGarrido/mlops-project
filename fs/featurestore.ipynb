{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf7d87c-ebff-456b-8e90-313c19133329",
   "metadata": {},
   "source": [
    "# üë©üèΩ‚Äçüíªüõí Vertex AI Feature Store \n",
    "\n",
    "O Feature Store da Vertex AI oferece um reposit√≥rio centralizado para organizar, armazenar e exibir recursos de ML.\n",
    "\n",
    "Um `featurestore` central permite que as organiza√ß√µes compartilhem, descubram e utilizem novamente atributos de ML com efici√™ncia, o que pode aumentar a velocidade de desenvolvimento e implanta√ß√£o de novos aplicativos de ML.\n",
    "\n",
    "Neste laborat√≥rio, vamos entender os principios fundamentais de um Feature Store e entender de forma pr√°tica como podemos utilizar dessa estrutura para gerenciar features de modelos de Machine Learning.\n",
    "\n",
    "Dispon√≠vel em: https://cloud.google.com/vertex-ai/docs/featurestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d968de-58b1-4d2d-a127-9b13ec44f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import sklearn\n",
    "from google.cloud import aiplatform\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc1cc14-9b41-421c-b2e8-97ec7458f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo vari√°veis globais\n",
    "PROJECT = \"garrido-ml-demos\"\n",
    "LOCATION = \"us-central1\"\n",
    "FEATURESTORE_NAME = \"iris_fs\"\n",
    "ENTITY_TYPE = \"id\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc8958-2683-4316-8dd5-d0e63f717777",
   "metadata": {},
   "source": [
    "## üå∫ Carregando e entendendo o conjunto de dados: Iris Dataset\n",
    "O Iris Dataset cont√©m quatro caracter√≠sticas (comprimento e largura das s√©palas e p√©talas) de 50 amostras de tr√™s esp√©cies de Iris (Iris setosa, Iris virginica e Iris versicolor). Essas medidas foram utilizadas para criar um modelo linear discriminante para classificar as esp√©cies. O conjunto de dados √© freq√ºentemente utilizado na minera√ß√£o de dados, exemplos de classifica√ß√£o e agrupamento e para testar algoritmos.\n",
    "\n",
    "Neste laborat√≥rio, trabalharemos com a biblioteca `scikit-learn` para realizar a ingest√£o do dataset e construiremos algumas amostras, introduzindo uma certa quantidade de ru√≠do, para simular pequenas diferen√ßas hist√≥ricas nos nossos dados (de forma a representar um pouco melhor um cen√°rio real de armazenamento de features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61f984-95be-4711-8cfe-0a1558db879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o Iris Datasets \n",
    "iris = load_iris()\n",
    "\n",
    "# Construindo Dataframe\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                 columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\n",
    "columns = ['id', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species', 'targets']\n",
    "\n",
    "# Adicionando id das flores e timestamp\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = columns\n",
    "\n",
    "df['id'] = df['id'].apply(lambda x: f'flower_{x}')\n",
    "df['timestamp'] = pd.Timestamp(datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a16452-6b3c-496f-943d-bfea685cdf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando amostras de features\n",
    "samples = 50\n",
    "\n",
    "# Instanciando uma c√≥pia do dataframe\n",
    "stage = df.copy()\n",
    "\n",
    "for day in range(samples):\n",
    "    # Gerando c√≥pias para introdu√ß√£o de ru√≠do nos dados\n",
    "    sample = df.copy()\n",
    "    \n",
    "    # Definindo marcas de timestamp retr√≥gradas para cada amostra\n",
    "    sample['timestamp'] = sample['timestamp'].apply(lambda x: x - timedelta(days=1))\n",
    "    \n",
    "    # Adicionando ru√≠do √†s features\n",
    "    sample[columns[1:-2]] += random.uniform(0, .5)\n",
    "    \n",
    "    # Concatenando as amostras conforme s√£o geradas\n",
    "    df = pd.concat([stage, sample]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f70d0-c9bd-496a-b988-929df5aba0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>targets</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-25 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>5.311500</td>\n",
       "      <td>3.711500</td>\n",
       "      <td>1.611500</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-24 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>5.783277</td>\n",
       "      <td>4.183277</td>\n",
       "      <td>2.083277</td>\n",
       "      <td>0.883277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-23 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>6.227935</td>\n",
       "      <td>4.627935</td>\n",
       "      <td>2.527935</td>\n",
       "      <td>1.327935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-22 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>6.248496</td>\n",
       "      <td>4.648496</td>\n",
       "      <td>2.548496</td>\n",
       "      <td>1.348496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-21 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>6.360848</td>\n",
       "      <td>4.760848</td>\n",
       "      <td>2.660848</td>\n",
       "      <td>1.460848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-20 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>6.481017</td>\n",
       "      <td>4.881017</td>\n",
       "      <td>2.781017</td>\n",
       "      <td>1.581017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-19 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>6.578152</td>\n",
       "      <td>4.978152</td>\n",
       "      <td>2.878152</td>\n",
       "      <td>1.678152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-18 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>6.762937</td>\n",
       "      <td>5.162937</td>\n",
       "      <td>3.062937</td>\n",
       "      <td>1.862937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-17 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>7.024087</td>\n",
       "      <td>5.424087</td>\n",
       "      <td>3.324087</td>\n",
       "      <td>2.124087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-16 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>7.353316</td>\n",
       "      <td>5.753316</td>\n",
       "      <td>3.653316</td>\n",
       "      <td>2.453316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-15 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>7.551740</td>\n",
       "      <td>5.951740</td>\n",
       "      <td>3.851740</td>\n",
       "      <td>2.651740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-14 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>7.787909</td>\n",
       "      <td>6.187909</td>\n",
       "      <td>4.087909</td>\n",
       "      <td>2.887909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-13 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>8.208414</td>\n",
       "      <td>6.608414</td>\n",
       "      <td>4.508414</td>\n",
       "      <td>3.308414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-12 17:09:41.443744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_0</td>\n",
       "      <td>8.339188</td>\n",
       "      <td>6.739188</td>\n",
       "      <td>4.639188</td>\n",
       "      <td>3.439188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-11 17:09:41.443744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sepal_length  sepal_width  petal_length  petal_width  species  \\\n",
       "0  flower_0      5.100000     3.500000      1.400000     0.200000      0.0   \n",
       "0  flower_0      5.311500     3.711500      1.611500     0.411500      0.0   \n",
       "0  flower_0      5.783277     4.183277      2.083277     0.883277      0.0   \n",
       "0  flower_0      6.227935     4.627935      2.527935     1.327935      0.0   \n",
       "0  flower_0      6.248496     4.648496      2.548496     1.348496      0.0   \n",
       "0  flower_0      6.360848     4.760848      2.660848     1.460848      0.0   \n",
       "0  flower_0      6.481017     4.881017      2.781017     1.581017      0.0   \n",
       "0  flower_0      6.578152     4.978152      2.878152     1.678152      0.0   \n",
       "0  flower_0      6.762937     5.162937      3.062937     1.862937      0.0   \n",
       "0  flower_0      7.024087     5.424087      3.324087     2.124087      0.0   \n",
       "0  flower_0      7.353316     5.753316      3.653316     2.453316      0.0   \n",
       "0  flower_0      7.551740     5.951740      3.851740     2.651740      0.0   \n",
       "0  flower_0      7.787909     6.187909      4.087909     2.887909      0.0   \n",
       "0  flower_0      8.208414     6.608414      4.508414     3.308414      0.0   \n",
       "0  flower_0      8.339188     6.739188      4.639188     3.439188      0.0   \n",
       "\n",
       "  targets                  timestamp  \n",
       "0  setosa 2022-06-25 17:09:41.443744  \n",
       "0  setosa 2022-06-24 17:09:41.443744  \n",
       "0  setosa 2022-06-23 17:09:41.443744  \n",
       "0  setosa 2022-06-22 17:09:41.443744  \n",
       "0  setosa 2022-06-21 17:09:41.443744  \n",
       "0  setosa 2022-06-20 17:09:41.443744  \n",
       "0  setosa 2022-06-19 17:09:41.443744  \n",
       "0  setosa 2022-06-18 17:09:41.443744  \n",
       "0  setosa 2022-06-17 17:09:41.443744  \n",
       "0  setosa 2022-06-16 17:09:41.443744  \n",
       "0  setosa 2022-06-15 17:09:41.443744  \n",
       "0  setosa 2022-06-14 17:09:41.443744  \n",
       "0  setosa 2022-06-13 17:09:41.443744  \n",
       "0  setosa 2022-06-12 17:09:41.443744  \n",
       "0  setosa 2022-06-11 17:09:41.443744  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando resultado do incremento de amostras para um id espec√≠fico\n",
    "df.loc[df['id'] == 'flower_0'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f16d2d-0cd0-47a2-8bd0-616dd3174f72",
   "metadata": {},
   "source": [
    "## üß± Inicializando um Feature Store\n",
    "\n",
    "Uma vez definido o nosso conjunto de dados hist√≥rico, √© poss√≠vel inicializar um novo Feature Store de forma bem simples, utilizando o SDK da Vertex AI.\n",
    "\n",
    "O Feature Store provisionar√° uma infraestrutura distribu√≠da (baseada em quantidades de n√≥s de computa√ß√£o), escal√°vel e altamente dispon√≠vel para que tenhamos as nossas features dispon√≠veis para recupera√ß√£o de `baixa lat√™ncia` e tamb√©m de forma `hist√≥rica`, sendo estas op√ß√µes definidas por dois canais, chamados `online` e `offline` Feature Store, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ccf06-cbd3-4b5a-a24a-b8ed337dab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando Vertex AI\n",
    "aiplatform.init(project=PROJECT, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b26c83-25be-485c-ad18-9cff8b63289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Featurestore\n",
      "Create Featurestore backing LRO: projects/348385944272/locations/us-central1/featurestores/iris_fs/operations/1038639984002727936\n",
      "Featurestore created. Resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs\n",
      "To use this Featurestore in another session:\n",
      "featurestore = aiplatform.Featurestore('projects/348385944272/locations/us-central1/featurestores/iris_fs')\n"
     ]
    }
   ],
   "source": [
    "# Criando o Feature Store\n",
    "fs = aiplatform.Featurestore.create(\n",
    "        featurestore_id=FEATURESTORE_NAME,\n",
    "        online_store_fixed_node_count=1,\n",
    "        sync=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0580d-a943-48e3-8fcf-16b42643936b",
   "metadata": {},
   "source": [
    "## üë∑üèΩ‚Äç‚ôÄÔ∏è Realizando a ingest√£o de features para o BigQuery\n",
    "\n",
    "A partir do Iris dataset em mem√≥ria (i.e., o nosso `Pandas Dataframe`), podemos gerar um arquivo `Parquet` de forma bem simples para persistir os dados de forma bin√°ria no disco. A partir disso, ser√° poss√≠vel realizar um processo de ingest√£o em batch para o `BigQuery`, um processo *sem custo* que disponibilizar√° os nossos dados em uma estrutura serverless, de armazenamento colunar, com baixo custo e orientada √† recupera√ß√£o e processamento massivo de dados. \n",
    "\n",
    "O Vertex AI Feature Store possui mecanismos de ingest√£o de features em batch a partir de arquivos bin√°rios no Google Cloud Storage, tabelas no BigQuery e Pandas Dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ecaa00-5640-485f-9de0-4dd97728e939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'garrido-ml-demos:iris' already exists.\n",
      "Dataset j√° existente\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Vamos come√ßar criando uma camada l√≥gica de dados no BigQuery, o nosso dataset\n",
    "{\n",
    "    bq --location=us-central1 mk -d iris\n",
    "} || { # catch\n",
    "    echo \"Dataset j√° existente\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441401d-f0ff-4a8e-a390-ccf507e3b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 969.56query/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "# Em seguida, vamos garantir que a nossa tabela ser√° recriada do zero\n",
    "DROP TABLE IF EXISTS iris.iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bce486-617c-48bc-b669-6759ecc2ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 843.25query/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "# Vamos definir a nossa tabela, utilizando o statement DDL do BigQuery\n",
    "CREATE OR REPLACE TABLE iris.iris(\n",
    "    id STRING,\n",
    "    petal_length FLOAT64,\n",
    "    sepal_length FLOAT64,\n",
    "    petal_width FLOAT64,\n",
    "    sepal_width FLOAT64,\n",
    "    species FLOAT64,\n",
    "    targets STRING,\n",
    "    timestamp TIMESTAMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47ab38-93ae-4f25-b166-5f6404b63d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo os dados em Parquet para realizar ingest√£o\n",
    "df.to_parquet('features.parquet.gzip',\n",
    "              compression='gzip',\n",
    "             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd601f-cd73-4da4-ae8e-1d1eb5b6d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload complete.\n",
      "Waiting on bqjob_r3ba7f803b2835ac9_000001819bd7e764_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bq load \\\n",
    "    --source_format=PARQUET \\\n",
    "    iris.iris \\\n",
    "    features.parquet.gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c13b61-3efc-408c-996f-761d2d391321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 1013.85query/s]                        \n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7650/7650 [00:01<00:00, 6773.32rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>targets</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_23</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-25 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flower_23</td>\n",
       "      <td>5.662628</td>\n",
       "      <td>9.062628</td>\n",
       "      <td>4.462628</td>\n",
       "      <td>7.262628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-08 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flower_6</td>\n",
       "      <td>2.083277</td>\n",
       "      <td>5.283277</td>\n",
       "      <td>0.983277</td>\n",
       "      <td>4.083277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-23 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flower_17</td>\n",
       "      <td>2.083277</td>\n",
       "      <td>5.783277</td>\n",
       "      <td>0.983277</td>\n",
       "      <td>4.183277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-23 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flower_18</td>\n",
       "      <td>2.383277</td>\n",
       "      <td>6.383277</td>\n",
       "      <td>0.983277</td>\n",
       "      <td>4.483277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>2022-06-23 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>flower_89</td>\n",
       "      <td>13.144353</td>\n",
       "      <td>14.644353</td>\n",
       "      <td>10.444353</td>\n",
       "      <td>11.644353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>2022-05-22 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>flower_94</td>\n",
       "      <td>13.344353</td>\n",
       "      <td>14.744353</td>\n",
       "      <td>10.444353</td>\n",
       "      <td>11.844353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>2022-05-22 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>flower_96</td>\n",
       "      <td>13.344353</td>\n",
       "      <td>14.844353</td>\n",
       "      <td>10.444353</td>\n",
       "      <td>12.044353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>2022-05-22 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>flower_97</td>\n",
       "      <td>13.444353</td>\n",
       "      <td>15.344353</td>\n",
       "      <td>10.444353</td>\n",
       "      <td>12.044353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>2022-05-22 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>flower_99</td>\n",
       "      <td>13.244353</td>\n",
       "      <td>14.844353</td>\n",
       "      <td>10.444353</td>\n",
       "      <td>11.944353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>2022-05-22 17:09:41.443744+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7650 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  petal_length  sepal_length  petal_width  sepal_width  \\\n",
       "0     flower_23      1.700000      5.100000     0.500000     3.300000   \n",
       "1     flower_23      5.662628      9.062628     4.462628     7.262628   \n",
       "2      flower_6      2.083277      5.283277     0.983277     4.083277   \n",
       "3     flower_17      2.083277      5.783277     0.983277     4.183277   \n",
       "4     flower_18      2.383277      6.383277     0.983277     4.483277   \n",
       "...         ...           ...           ...          ...          ...   \n",
       "7645  flower_89     13.144353     14.644353    10.444353    11.644353   \n",
       "7646  flower_94     13.344353     14.744353    10.444353    11.844353   \n",
       "7647  flower_96     13.344353     14.844353    10.444353    12.044353   \n",
       "7648  flower_97     13.444353     15.344353    10.444353    12.044353   \n",
       "7649  flower_99     13.244353     14.844353    10.444353    11.944353   \n",
       "\n",
       "      species     targets                        timestamp  \n",
       "0         0.0      setosa 2022-06-25 17:09:41.443744+00:00  \n",
       "1         0.0      setosa 2022-06-08 17:09:41.443744+00:00  \n",
       "2         0.0      setosa 2022-06-23 17:09:41.443744+00:00  \n",
       "3         0.0      setosa 2022-06-23 17:09:41.443744+00:00  \n",
       "4         0.0      setosa 2022-06-23 17:09:41.443744+00:00  \n",
       "...       ...         ...                              ...  \n",
       "7645      1.0  versicolor 2022-05-22 17:09:41.443744+00:00  \n",
       "7646      1.0  versicolor 2022-05-22 17:09:41.443744+00:00  \n",
       "7647      1.0  versicolor 2022-05-22 17:09:41.443744+00:00  \n",
       "7648      1.0  versicolor 2022-05-22 17:09:41.443744+00:00  \n",
       "7649      1.0  versicolor 2022-05-22 17:09:41.443744+00:00  \n",
       "\n",
       "[7650 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "SELECT * FROM iris.iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f18e35-0bea-4ed3-9cdd-e7e5f16be0f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üë∑üèø Definindo as features do Feature Store\n",
    "\n",
    "Uma vez definido o reposit√≥rio de staging de features no BigQuery, podemos executar a cria√ß√£o das `features` pela pr√≥pria UI do Feature Store. \n",
    "\n",
    "As features representam informa√ß√µes que ser√£o armazenada dentro da estrutura l√≥gica de uma `entidade` (um identificador, tal como um id, um SKU, um nome, etc.), ou seja, para cada entidade, teremos n features, seguidas de um timestamp, que representa um carimbo do qu√£o atual √© aquele valor dentro do Feature Store:\n",
    "\n",
    "```Entidade``` --> [`feature_1`, `feature_2`, `...`, `feature_n`] [`timestamp`]\n",
    "\n",
    "Podemos nos basear em um exemplo bem simples, presente na documenta√ß√£o da Vertex Feature Store e que representa a associa√ß√£o de caracter√≠sticas de um filme (features) a uma entidade (o id do filme):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7a525-c093-4d38-8833-533692bed9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating EntityType\n",
      "Create EntityType backing LRO: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id/operations/3017972020232060928\n",
      "EntityType created. Resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id\n",
      "To use this EntityType in another session:\n",
      "entity_type = aiplatform.EntityType('projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.featurestore.entity_type.EntityType object at 0x7fd4e206bad0> \n",
       "resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando uma nova entidade (id)\n",
    "aiplatform.EntityType.create(\n",
    "        entity_type_id=ENTITY_TYPE, featurestore_name=FEATURESTORE_NAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf78160-75b7-45a2-b0e7-3903bc0f638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o Entity Type de IDs (criado pela UI do Feature Store)\n",
    "ids = aiplatform.featurestore.EntityType(\n",
    "    entity_type_name=ENTITY_TYPE, featurestore_id=FEATURESTORE_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b3eaf-b024-4d65-8f9b-799c6a15af8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal_length', 'sepal_width', 'petal_length', 'petal_width']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns[1:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa575b22-f2ea-4608-9af1-a4cd68486429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch creating features EntityType entityType: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id\n",
      "Batch create Features EntityType entityType backing LRO: projects/348385944272/locations/us-central1/featurestores/iris_fs/operations/8514615365437751296\n",
      "EntityType entityType Batch created features. Resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.featurestore.entity_type.EntityType object at 0x7fd4e207f310> \n",
       "resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo e criando as features no Feature Store (de forma s√≠ncrona)\n",
    "FEATURES = columns[1:-2]\n",
    "\n",
    "FEATURE_CONFIGS = {\n",
    "        feature : {\n",
    "            \"value_type\": \"DOUBLE\",\n",
    "            \"description\": f\"Representa a {feature} da flor\"\n",
    "        } for feature in FEATURES\n",
    "}\n",
    "\n",
    "ids.batch_create_features(feature_configs=FEATURE_CONFIGS, sync=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbec258-fcc5-4111-ac12-e8759e8b3706",
   "metadata": {},
   "source": [
    "## üë∑üèæ‚Äç‚ôÄÔ∏è Ingest√£o e Recupera√ß√£o de Features \n",
    "\n",
    "Agora vamos pular rapidinho pra console e definir um novo job de ingest√£o de features a partir do `BigQuery` para posteriormente poder recuper√°-las do canal de online serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec93f9-d2d5-4f0a-9897-7d6395525b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing EntityType feature values: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id\n",
      "Import EntityType feature values backing LRO: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id/operations/426150434680340480\n",
      "EntityType feature values imported. Resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.featurestore.entity_type.EntityType object at 0x7fd4e207f310> \n",
       "resource name: projects/348385944272/locations/us-central1/featurestores/iris_fs/entityTypes/id"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um job de ingest√£o de features do source (BigQuery) para o Feature Store de forma s√≠ncrona\n",
    "ids.ingest_from_bq(\n",
    "    feature_ids=FEATURES,\n",
    "    feature_time=\"timestamp\",\n",
    "    bq_source_uri=f\"bq://{PROJECT}.iris.iris\",\n",
    "    entity_id_field=\"id\",\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74485bdf-54cd-48ca-9e69-0b34a5821ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ap√≥s finalizado o job de ingest√£o, vamos recuperar features para um determinado id\n",
    "entity_id = \"flower_113\"\n",
    "features = ids.read(entity_ids=[entity_id], feature_ids=[\"*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d8446-7a00-4f95-bfe2-a2af7e4cf599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_id</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>sepal_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flower_113</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entity_id  petal_length  petal_width  sepal_width  sepal_length\n",
       "0  flower_113           5.0          2.0          2.5           5.7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as features recuperadas\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69c68b-fc9f-4825-927e-1e918a167eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando features para previs√£o\n",
    "np.array([features.to_dict(\"split\")[\"data\"][0][1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4639b29-ad9b-41ac-be9a-16294846dc0d",
   "metadata": {},
   "source": [
    "## üë©üèæ‚Äçüî¨ Treinando um classificador \n",
    "\n",
    "Para que possamos posteriormente consumir as nossas features para um prop√≥sito de infer√™ncias, vamos utilizar o Iris Dataset que est√° armazenado em mem√≥ria para treinar um classificador do tipo `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692d502-9d95-4cba-a545-5af1c614b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcca39c-85d2-41d1-adc1-1880ca74576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aabd56-9156-4fe2-b6be-b914dc36d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistindo o modelo em disco\n",
    "filename = \"model.pkl\"\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a16cb3-7e08-4ee0-9ab9-f1d72b1d15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando score do modelo para os dados de teste\n",
    "clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f80ab8-b96a-448d-be68-dfcf93ccdc53",
   "metadata": {},
   "source": [
    "## üë©üèæ‚Äçüíª Realizando predi√ß√µes para entidades recuperadas do Feature Store\n",
    "\n",
    "Agora que j√° temos um modelo treinado, podemos consumir as nossasfeatures do Feature store para realizar predi√ß√µes.\n",
    "\n",
    "Com isso, √© poss√≠vel recuperar a informa√ß√£o de maneira centralizada e r√°pida para infer√™ncia a partir de alguma dada entidade.\n",
    "\n",
    "√â v√°lido que ressaltar que o m√©todo de leitura `read` de uma `entidade` no Feature Store sempre recupera o **timestamp mais atual para o serving online.**\n",
    "\n",
    "A depender da disponibilidade do Feature Store, √© poss√≠vel perceber uma maior lat√™ncia nas primeiras requisi√ß√µes, mas que rapidamente se ajustam, de modo que a estrutura possa receber uma quantidade massiva de requisi√ß√µes subsequentes, sem perda de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b116cc2-2f02-4f92-b3d4-1eaadde9a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexa√ß√£o do target\n",
    "indexes = pd.Series(df.targets.unique()).to_dict()\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2ae25-7c02-4163-a233-b54308820ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando uma entidade\n",
    "entity = \"flower_34\"\n",
    "\n",
    "# Recuperando as features\n",
    "features = ids.read(entity_ids=[entity], feature_ids=[\"*\"]).to_dict(\"split\")[\"data\"][0][1:]\n",
    "\n",
    "# Resultado da predi√ß√£o\n",
    "print(f'A flor {entity} √© do tipo \"{indexes[clf.predict(np.array([features]))[0]]}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aface129-69d6-4750-ac20-407612d991b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando 10 infer√™ncias s√≠ncronas em s√©rie\n",
    "from random import randrange\n",
    "\n",
    "for _ in range(30):\n",
    "    entity = f\"flower_{randrange(150)}\"\n",
    "    # Recuperando as features\n",
    "    features = ids.read(entity_ids=[entity], feature_ids=[\"*\"]).to_dict(\"split\")[\"data\"][0][1:]\n",
    "\n",
    "    # Resultado da predi√ß√£o\n",
    "    print(f'A flor {entity} √© do tipo \"{indexes[clf.predict([features])[0]]}\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3dbf9-6479-40c0-b035-2f5fccd96028",
   "metadata": {},
   "source": [
    "## üïí Point-in-time Recovery\n",
    "\n",
    "Atrav√©s do Feature Store, tamb√©m √© poss√≠vel recuperar features em batch para diferentes timestamps. √â atrav√©s de um canal denominado `Offline Feature Store` que podemos consumir de slices de features em diferentes intervalos de timestamp e export√°-los para arquivos bin√°rios no Cloud Storage, tabelas no BigQuery ou Pandas Dataframes. \n",
    "\n",
    "Esse processo refor√ßa a ideia da constru√ß√£o de um reposit√≥rio centralizado de features, com caracter√≠sticas h√≠bridas, proporcionando baixa lat√™ncia de recupera√ß√£o e consist√™ncia de recupera√ß√£o hist√≥rica de valores utilizando uma estrutura unificada. \n",
    "\n",
    "No exemplo a seguir, vamos recuperar features em batch em um timestamp retroativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618606c-f630-4dc5-a133-2db3db3a9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o Feature Store\n",
    "fs = aiplatform.featurestore.Featurestore(featurestore_name=FEATURESTORE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a326e216-110f-47b2-ac19-c05163d74609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo features para recupera√ß√£o dentro de entity types\n",
    "SERVING_FEATURE_IDS = {\n",
    "    \"id\": [\"*\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9946ba-b3b1-4b2c-af83-f7e6d55cea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um timestamp de recupera√ß√£o point in time\n",
    "point_in_time = pd.Timestamp(datetime.today() - timedelta(days=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32ddb85-77ab-4b32-a282-c1dd6752d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo esquema de recupera√ß√£o Point-in-Time para uma determinado entidade\n",
    "entity = \"flower_139\"\n",
    "\n",
    "pit_config = pd.DataFrame(\n",
    "    data=[\n",
    "        {\n",
    "        \"id\": entity,\n",
    "        \"timestamp\": point_in_time\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8a635-a6fb-40b8-a035-9cf2ad788bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando features Point-in-Time do offline Feature Store\n",
    "pit_features = fs.batch_serve_to_df(\n",
    "    serving_feature_ids=SERVING_FEATURE_IDS,\n",
    "    read_instances_df=pit_config,\n",
    ")\n",
    "\n",
    "# Visualizando features Point-in-Time recuperadas\n",
    "pit_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f8fb0-dea8-443a-afea-ab7a4f9085cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando as features mais recentes para compara√ß√£o\n",
    "ids.read(entity_ids=[entity], feature_ids=[\"*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ac6f1-843b-43e1-a431-e0c1c4043bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo esquema de recupera√ß√£o hist√≥rico para todos os entities\n",
    "historical_config = pd.DataFrame(\n",
    "    data=[\n",
    "        {\n",
    "        \"id\": [f\"flower_{n}\" for n in range(150)],\n",
    "        \"timestamp\": pd.date_range(start=\"2022-06-10\",end=\"2022-06-15\").tolist()\n",
    "        }\n",
    "    ],\n",
    ").explode([\"id\"]).explode([\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd816a-5964-4332-8cb0-19ca7b0519df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando features hist√≥ricas do offline Feature Store\n",
    "historical_features = fs.batch_serve_to_df(\n",
    "    serving_feature_ids=SERVING_FEATURE_IDS,\n",
    "    read_instances_df=historical_config,\n",
    ")\n",
    "\n",
    "# Visualizando features hist√≥ricas recuperadas \n",
    "historical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e0f9c-f50d-4033-a941-fb75f0aa29cb",
   "metadata": {},
   "source": [
    "## üë®üèΩ‚Äçüéì Conclus√£o\n",
    "\n",
    "Neste laborat√≥rio, pudemos entender um pouco melhor sobre os conceitos b√°sicos de um Feature Store, bem como:\n",
    "- Componentes da Arquitetura (canal `online` e `offline`)\n",
    "- Modelo de dados do Feature Store (`featurestores`, `entidades`, `features`, `timestamps`)\n",
    "- Como `ingerir/recuperar` features do Vertex AI Feature Store, para infer√™ncia e point-in-time check\n",
    "\n",
    "Para excluir o feature store, siga para as pr√≥ximas c√©lulas.\n",
    "Time to clean! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbaf99-25a1-4982-b2e9-9590051667c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.delete(sync=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49fcf2-48d3-4579-9862-a545716ff444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m89"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
